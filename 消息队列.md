#### Kafka

分布式流处理框架，作为企业级的消息引擎被广泛使用。Kafka由多个broker组成，每个broker是一个节点，代理保存消息的中转站，Producers往Brokers里面的指定Topic中写消息，Consumers从Brokers里面拉取指定Topic的消息，然后进行业务处理；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。

![](https://sz-note-md.oss-cn-beijing.aliyuncs.com/imgkafka图.png)



#### zookeeper在Kafka的作用

选举leader（controller）和检查broker是否存活



#### Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么

ISR: In-Sync Replicas 同步队列副本
AR: Assigned Replicas 所有副本
ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。



#### Kafka follower如何与leader同步数据 

简述版：follower 从leader 发送pull请求并附带上follower的offset位置，leader响应follower请求返回HW(high watermark）和LEO（log end offset位置），follower接收到响应将数据写入到follower的log文件，并返回ack给leader

https://www.cnblogs.com/youngchaolin/p/12641463.html



#### HW和LEO如何工作





#### 什么情况下一个 broker 会从 ISR中踢出去

leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护 ，如果一个follower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其从ISR中移除 。



####  Kafka 为什么那么快 

分写入数据和读取数据两方面入手

##### 写入操作

1. Cache Filesystem Cache PageCache缓存，用操作系统的Page来实现文件到物理内存的直接映射。完成映射之后，你对物理内存的操作会被同步到硬盘上，存在缺陷不可靠，数据并没有被真正地写入到硬盘中，操作系统会在程序主动调用flush命令的时候才会把数据真正地写入到硬盘中。

2. 顺序写 由于现代的操作系统提供了预读和写技术，磁盘的顺序写大多数情况下比随机写内存还要快。因为写入硬盘会有一个寻址-》写入的过程，寻址的操作相对而已消耗机械操作，随意随机写入会增加不必要的机械操作，反面对比出顺序写入省去了部分机械操作

##### 读取操作

1. Zero-copy 零拷技术减少拷贝次数

2. Batching of Messages 批量量处理。合并小的请求，然后以流的方式进行交互，直顶网络上限。

3. Pull 拉模式 使用拉模式进行消息的获取消费，与消费端处理能力相符。

https://www.cnblogs.com/yanggb/p/11063942.html



#### Kafka producer 发送数据，ack  为 0， 1， -1 的时候代表啥， 设置 -1 的时候，什么情况下，leader 会认为一条消息 commit了

- 1（默认） 数据发送到Kafka后，经过leader成功接收消息的的确认，就算是发送成功了。在这种情况下，如果leader宕机了，则会丢失数据。
- 0 生产者将数据发送出去就不管了，不去等待任何返回。这种情况下数据传输效率最高，但是数据可靠性确是最低的。
- -1 producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高



#### Kafka 如何优化producer写入速度

 1. 增加线程，broker数量，partition数量
 2. 提高batch.size配置
 3. 设置ack=0不设置确认，如果延迟增大的话可以增大 num.replica.fetchers（follower 同步数据的线程数）来调解；



#### 消费者如何不自动提交偏移量，由应用提交？

 auto.commit.offset 设为 false，然后在处理一批消息后 commitSync() 或者异步提交 commitAsync()

```
ConsumerRecords<> records = consumer.poll();
for (ConsumerRecord<> record : records){
    。。。
    tyr{
        consumer.commitSync()
    }
    。。。
}
```



#### 如果leader crash时，ISR为空怎么办

Kafka在Broker端提供了一个配置参数：unclean.leader.election,这个参数有两个值：
true：允许不同步副本成为leader，由于不同步副本的消息较为滞后，此时成为leader，可能会出现消息不一致的情况。
false(默认，版本0.11之后)：不允许不同步副本成为leader，此时如果发生ISR列表为空，会一直等待旧leader恢复，降低了可用性。



#### Kafka的message格式是什么样的

一个Kafka的Message由一个固定长度的header和一个变长的消息体body组成。

header = magic+CRCS32+attributes(magic为0时不存在，为1时存在，保存一些相关属性，比如是否压缩、压缩格式等等)



#### kafka中consumer group 是什么概念

同样是逻辑上的概念，是Kafka实现单播和广播两种消息模型的手段。同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。



### Kafka中的消息是否会丢失和重复消费

要确定Kafka的消息是否丢失或重复，从两个方面分析入手：消息发送和消息消费。

**1、消息发送**

     Kafka消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过producer.type属性进行配置。Kafka通过配置request.required.acks属性来确认消息的生产：

1. *0---表示不进行消息接收是否成功的确认；*
2. *1---表示当Leader接收成功时确认；*
3. *-1---表示Leader和Follower都接收成功时确认；*

综上所述，有6种消息生产的情况，下面分情况来分析消息丢失的场景：

（1）acks=0，不和Kafka集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，**消息可能丢失**；

（2）acks=1、同步模式下，只有Leader确认接收成功后但挂掉了，副本没有同步，**数据可能丢失**；

**2、消息消费**

Kafka消息消费有两个consumer接口，Low-level API和High-level API：

1. Low-level API：消费者自己维护offset等值，可以实现对Kafka的完全控制；
2. High-level API：封装了对parition和offset的管理，使用简单；

如果使用高级接口High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“*诡异*”的消失了；

**解决办法**：

    针对消息丢失：同步模式下，确认机制设置为-1，即让消息写入Leader和Follower之后再确认消息发送成功；异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生产者一直处于阻塞状态；
    
    针对消息重复：将消息的唯一标识保存到外部介质中，每次消费时判断是否处理过即可。

消息重复消费及解决参考：https://www.javazhiyin.com/22910.html



#### 为什么Kafka不支持读写分离

主读主写，因为follower同步leader的数据，如果读写分离，可能造成数据不一致，读写分离场景适用于读多写少，Kafka的应用场景并不适用



#### Kafka中是怎么体现消息顺序性的？

整个topic不保证有序，但是partition写入是有序的，因为partition会被单个group中的consumer消费，所以也能保持有序，如果要保证整个topic有序，则只能有一个partition;不同 partition 之间不能保证顺序。但是绝大多数用户都可以通过 message key 来定义，因为同一个 key 的 message 可以保证只发送到同一个 partition。Kafka 中发送 1 条消息的时候，可以指定(topic, partition, key) 3 个参数。partiton 和 key 是可选的。如果你指定了 partition，那就是所有消息发往同 1个 partition，就是有序的。并且在消费端，Kafka 保证，1 个 partition 只能被1 个 consumer 消费。或者你指定 key（ 比如 order id），具有同 1 个 key 的所有消息，会发往同 1 个 partition。



#### 如何提高Kafka消费能力

1. 保证业务处理复杂度耗时较短
2. 提高消费端的消费能力，增加consumer数量，同时也要增加partition数量，因为partition和consumer是一一对应的
3. 批量消费，批量拉取数据处理，需要设置合理的Kafka超时时间





#### 如何保证消息不丢失

##### 1. 检查消息丢失的方法



>  利用消息队列的有序性来验证是否有消息丢失。在发送端，每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的连续性。

##### 2. 确保消息可靠传递

>  一条消息从生产到消费完成这个过程，可以划分三个阶段，如下图所示

![](https://sz-note-md.oss-cn-beijing.aliyuncs.com/img1.png)

- 生产阶段：从消息在 Producer 创建出来，经过网络传输发送到 Broker 端，只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失
- 存储阶段：一般broker服务器不宕机，就不会出现消息丢失情况，但是如果服务器宕机，那么就有可能导致消息丢失，对于单个节点来说，可以在broker将数据写入磁盘后再返回ack给发送端。对于集群而言，则需要保证broker集群至少将消息发生到2个节点以上，再给客户端发送确认响应
- 消费阶段：消费阶段采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应

#### 如何避免消息重复消费

MQTT协议中，消息传递能提供三种服务质量标准，从低到高分别是

At most once:至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。

At least once:至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现

Exactly once:恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。

##### 解决办法

>  幂等性：任意多次执行所产生的影响均与一次执行的影响相同

接口做幂等性消费

#### 消息队列作用

削峰，异步，解耦